{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92338de6-cc45-4cff-8ece-ad37d46c9543",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7cba56-d837-4ff5-9828-fbb2fb6da06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c93c946-0df0-416d-abef-b2a6221e7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adffbf1-988a-4361-94af-237efdd6185d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parse Whitelist Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f706b4-e1e6-4e33-b6de-2e29006ae347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words_list(filenames):\n",
    "    result_ls = set()\n",
    "    for filename in filenames:\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f:\n",
    "                words = line.strip().split(',')\n",
    "                if len(words) == 1:\n",
    "                    result_ls.add(words[0])\n",
    "                else:\n",
    "                    result_ls.add(tuple(words))\n",
    "    return result_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a678d5b-1cc2-4762-a260-937cf5ee4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = read_words_list([\"whitelist/word1_w.txt\", \"whitelist/word2_w.txt\", \"whitelist/word3_w.txt\", \"whitelist/word4_w.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12068362-9576-4a64-99f9-11db25076389",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parse Blacklist Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6dee158-caeb-4993-88b6-3830fb8f20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl = read_words_list([\"blacklist/word1_b.txt\", \"blacklist/word2_b.txt\", \"blacklist/word3_b.txt\", \"blacklist/word4_b.txt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4362ab-6166-4be9-8db9-d7c2e246f3a1",
   "metadata": {},
   "source": [
    "# Parse incoming whitepapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f0a23a9-3240-4d05-90ee-0a32ade6fb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_whitepapers(filename, stopwords):\n",
    "    directory = \"../whitepapers/top20_whitepapers/\"\n",
    "    words_list = []\n",
    "    words_context_dict = {}\n",
    "    # context_tuples_ref = []\n",
    "    word_idx = 0\n",
    "    context_idx = 0\n",
    "    for entry in os.scandir(directory):\n",
    "        if (entry.path.endswith(filename) and entry.is_file()):\n",
    "            with open(entry.path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    # context_tuples_ref += [line]\n",
    "                    temp_words = extract_and_clean(line, stopwords)\n",
    "                    words_list.extend(temp_words)\n",
    "                    for i in range(len(temp_words)):\n",
    "                        words_context_dict[word_idx] = context_idx\n",
    "                        word_idx += 1\n",
    "                    context_idx += 1\n",
    "    return words_list, words_context_dict #, context_tuples_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd7b6eb-732b-4fcd-ae01-8426fa67ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_clean(line, stopwords):\n",
    "    # words = [x.strip() for x in re.split(',| |\\. |\\: ', line) if x]\n",
    "    # words = map(str.lower, words)\n",
    "    # words = [x.replace('-', '') for x in words]\n",
    "    words = word_tokenize(re.sub(r'[^\\w\\s]', '', line.lower()))\n",
    "    # words = [x.replace('-', '') for x in words]\n",
    "    words = [word for word in words if not word in stopwords]\n",
    "    # ADJ, ADJ_SAT, ADV, NOUN, VERB = 'a', 's', 'r', 'n', 'v'\n",
    "    words = [lemmatizer.lemmatize(w, pos='s') for w in words]\n",
    "    words = [lemmatizer.lemmatize(w, pos='n') for w in words]\n",
    "    words = [lemmatizer.lemmatize(w, pos='v') for w in words]\n",
    "    words = [lemmatizer.lemmatize(w, pos='a') for w in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "807447d2-e047-4d62-a052-12bd1068f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe(words, context_ref):\n",
    "    appearance_dict = {}\n",
    "    for i in range(len(words)):\n",
    "        appearance_dict.setdefault(words[i],[]).append(context_ref[i])\n",
    "    return list(set(words)), appearance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d79c4e9-f35b-4a1a-8ae4-d257aa5cabfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wl_bl_words(words, context_ref, wl, bl):\n",
    "    filtered_words = []\n",
    "    filtered_context = {}\n",
    "    for w in words:\n",
    "        if w in wl and w not in bl:\n",
    "            filtered_words.append(w)\n",
    "            filtered_context[w] = context_ref[w]\n",
    "    return filtered_words, filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab0bd2d0-071f-4125-93d8-d620b324c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca67487b-85dc-431c-bd87-b6d77a49bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Bitcoin.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796f9e9e-b5ae-41b7-b3e4-21b07b5d6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ls, words_context_dict = read_whitepapers(filename, stopwords_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c5c3698-1e45-46ea-b955-2ee67a8a4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_lookup_dict(lookup_dict, words, paper_name, appearance_dict):\n",
    "    for w in words:\n",
    "        lookup_dict.setdefault(w,[]).append((paper_name, appearance_dict[w]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f240bc-f220-4e29-ae42-072d7401b918",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b9bdb-f104-4ea3-84ee-b8f4033586d7",
   "metadata": {},
   "source": [
    "## Single word white list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e1e583-9fe3-48d6-8d0b-7bd8184c1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_words, deduped_appearance_dict = dedupe(words_ls, words_context_dict)\n",
    "wl_words, wl_appearance_dict = filter_wl_bl_words(deduped_words, deduped_appearance_dict, wl, bl)\n",
    "enrich_lookup_dict(lookup_dict, wl_words, filename, wl_appearance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62506ba-e74b-4149-833a-133e3fa4b170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['download',\n",
       " 'doublespending',\n",
       " 'coordination',\n",
       " 'adam',\n",
       " 'nakamoto',\n",
       " 'proc',\n",
       " 'internet',\n",
       " 'merkle',\n",
       " 'counterparty',\n",
       " 'online']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db45b1d-4db4-4735-9196-6569856ccacd",
   "metadata": {},
   "source": [
    "## 2-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9041b2f1-deb0-41b6-afb1-b23531028a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_words_2, deduped_appearance_dict_2 = dedupe(list(ngrams(words_ls, 2)), words_context_dict)\n",
    "wl_words_2, wl_appearance_dict_2 = filter_wl_bl_words(deduped_words_2, deduped_appearance_dict_2, wl, bl)\n",
    "enrich_lookup_dict(lookup_dict, wl_words_2, filename, wl_appearance_dict_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "703096ed-e172-43e4-a07c-05e021489ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('solution', 'propose'),\n",
       " ('traditional', 'bank'),\n",
       " ('failure', 'event'),\n",
       " ('signature', 'provide'),\n",
       " ('party', 'transact'),\n",
       " ('proofofwork', 'block'),\n",
       " ('control', 'majority'),\n",
       " ('attack', 'network'),\n",
       " ('check', 'transaction'),\n",
       " ('peertopeer', 'electronic')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl_words_2[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7dad5f-5352-4df3-9e94-1057c1db342a",
   "metadata": {},
   "source": [
    "## 3-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8aa6531-9fcc-4de0-9cc3-95f870333ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_words_3, deduped_appearance_dict_3 = dedupe(list(ngrams(words_ls, 3)), words_context_dict)\n",
    "wl_words_3, wl_appearance_dict_3 = filter_wl_bl_words(deduped_words_3, deduped_appearance_dict_3, wl, bl)\n",
    "enrich_lookup_dict(lookup_dict, wl_words_3, filename, wl_appearance_dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "307d80c8-bc7e-4bee-8daf-1720888cdba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('system', 'base', 'cryptographic'),\n",
       " ('computer', 'science', 'page'),\n",
       " ('simplify', 'payment', 'verification'),\n",
       " ('need', 'trust', 'third'),\n",
       " ('transaction', 'add', 'block'),\n",
       " ('acm', 'conference', 'computer'),\n",
       " ('electronic', 'cash', 'system'),\n",
       " ('key', 'private', 'key'),\n",
       " ('root', 'merkle', 'root'),\n",
       " ('key', 'public', 'key')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl_words_3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5112eb28-3d68-4fa0-bbdd-86e81c98d34a",
   "metadata": {},
   "source": [
    "## 4-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "731c1ca1-fd26-4f34-8321-f20a6a32b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_words_4, deduped_appearance_dict_4 = dedupe(list(ngrams(words_ls, 4)), words_context_dict)\n",
    "wl_words_4, wl_appearance_dict_4 = filter_wl_bl_words(deduped_words_4, deduped_appearance_dict_4, wl, bl)\n",
    "enrich_lookup_dict(lookup_dict, wl_words_4, filename, wl_appearance_dict_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d87f5aac-4799-42c8-8015-cee5d1ffc879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('payment', 'system', 'base', 'cryptographic'),\n",
       " ('bitcoin', 'peertopeer', 'electronic', 'cash'),\n",
       " ('electronic', 'payment', 'system', 'base'),\n",
       " ('acm', 'conference', 'computer', 'communication'),\n",
       " ('system', 'base', 'cryptographic', 'proof'),\n",
       " ('conference', 'computer', 'communication', 'security'),\n",
       " ('peertopeer', 'electronic', 'cash', 'system')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl_words_4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de0e64e6-92c0-41bc-8bde-9f384192b7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bitcoin.txt', [55])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_dict[('verify', 'one')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4e5c1f-52d6-4ab9-9612-83a95362e32a",
   "metadata": {},
   "source": [
    "# Aggregate & Look up context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f868f99f-4910-4a86-82ef-ede520b74a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_context_richer(lookup_dict, words, filename):\n",
    "    directory = \"../whitepapers/top20_whitepapers/\"\n",
    "    appearances = lookup_dict[words]\n",
    "    idx = 0\n",
    "    cache_doc = []\n",
    "    # Read the doc\n",
    "    for entry in os.scandir(directory):\n",
    "        if (entry.path.endswith(filename) and entry.is_file()):\n",
    "            with open(entry.path, \"r\") as f:\n",
    "                for line in f:\n",
    "                    cache_doc.append(line)\n",
    "    # For each white paper, read and print relevant contents\n",
    "    for appear in appearances:\n",
    "        idxs = appear[1]\n",
    "        for idx in idxs:\n",
    "            print(filename + \" [line \" + str(idx) + \"] : \")\n",
    "            if idx > 0:\n",
    "                print(cache_doc[idx - 1], end =\"\")\n",
    "            print(cache_doc[idx], end =\"\")\n",
    "            if idx < len(cache_doc) - 1:\n",
    "                print(cache_doc[idx + 1], end =\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab64271-1db3-4153-ba8b-2742cd15d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin.txt [line 346] : \n",
      "[5] S. Haber, W.S. Stornetta, \"Secure names for bit-strings,\" In Proceedings of the 4th ACM Conference \n",
      "on Computer and Communications Security, pages 28-35, April 1997.\n",
      "[6] A. Back, \"Hashcash - a denial of service counter-measure,\" \n"
     ]
    }
   ],
   "source": [
    "lookup_context_richer(lookup_dict, ('computer', 'communication', 'security'), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d4a8183-4f73-499a-b89d-de02620a0b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin.txt [line 82] : \n",
      "of-work system similar to Adam Back's Hashcash [6], rather than newspaper or Usenet posts. \n",
      "The proof-of-work involves scanning for a value that when hashed, such as with SHA-256, the \n",
      "hash begins with a number of zero bits.  The average work required is exponential in the number \n"
     ]
    }
   ],
   "source": [
    "lookup_context_richer(lookup_dict, 'sha256', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606a629f-840e-4be2-9830-f3a1acf30df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['download',\n",
       " 'doublespending',\n",
       " 'coordination',\n",
       " 'adam',\n",
       " 'nakamoto',\n",
       " 'proc',\n",
       " 'internet',\n",
       " 'merkle',\n",
       " 'counterparty',\n",
       " 'online']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_extracted_word = wl_words + wl_words_2 + wl_words_3 + wl_words_4\n",
    "agg_extracted_word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e252960-c2bd-45b4-9323-87f1e9606a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decision', 'make'),\n",
       " ('number', 'zero'),\n",
       " ('incentive', 'value'),\n",
       " ('output', 'value'),\n",
       " ('receive', 'one'),\n",
       " ('chain', 'extend'),\n",
       " ('computer', 'society'),\n",
       " ('node', 'control'),\n",
       " ('message', 'broadcast'),\n",
       " ('every', 'transaction'),\n",
       " ('pair', 'use'),\n",
       " ('public', 'key'),\n",
       " ('strong', 'control'),\n",
       " ('generate', 'new'),\n",
       " ('network', 'one'),\n",
       " ('someone', 'send'),\n",
       " ('number', 'block'),\n",
       " ('execute', 'transaction'),\n",
       " ('transaction', 'system'),\n",
       " ('value', 'hash'),\n",
       " ('system', 'work'),\n",
       " ('expend', 'resource'),\n",
       " ('block', 'chain'),\n",
       " ('node', 'support'),\n",
       " ('need', 'keep'),\n",
       " ('change', 'block'),\n",
       " ('block', 'add'),\n",
       " ('node', 'receive'),\n",
       " ('computer', 'communication'),\n",
       " ('network', 'follow')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_extracted_word[200:230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8f9bf-4fc8-46dc-9390-2646dfbb104c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
